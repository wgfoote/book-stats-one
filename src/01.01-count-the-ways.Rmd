
```{r , include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
options( digits = 2, scipen = 99999)
```

# Counting the Ways

## Plausibility, probability and information

According to Aristotle, if two claims are well-founded, their truth values can be ascertained. A plate is either green, or it is not. When thrown, the plate will land without a chip or it will break. If I claim that when I throw the plate, it will land with out a chip and you disagree, I can simply throw the plate to find out who was correct. One part of this is a mind game, a thought experiment a potential outcome. The other is a reality of actually throwing the plate and observing its status on landing. We will eventually call the mind-game a hypothesis and the reality a datum.

It is in disagreement that logical deduction might (plausibly) break down. There is no guarantee that the plate will break, or, for that matter, that it will chip. We must simply experiment with plate(s), green, blue or otherwise, to support the claim (or not). These claims arise in everyday life. For example, despite my poor performance in plate throwing in the past, there is no cogent reason to believe that it is absolutely, positively false that the plate I throw would land without a chip. There is a degree of acceeptance, of plausibility, in one side of the claim, and on the other as well. Certainly it is not as false as the claim that $2+2=5$ in base 10 arithmetic, or the patently spurious claim that true is false or my cat is a dog.

Claims about things that are neither definitely true nor definitely false arise in matters both mundane and consequential: producing weather reports, catching the bus, predicting the outcomes of elections, interpreting experimental vaccine results, and betting on sports games, throwing the plate, to name just a few.

So we would benefit from a method of comparing claims in these situations – which atmospheric model produces better predictions? What is the best source for predicting elections? Should I blow three times on my lucky dice, or is this all just a figment of my denial based imagination?

## Some Surprise

The goal, in all the cases above, is to guess about something that we don’t or can’t know directly, like the future, or the fundamental structure of the economy, or reasons why customer preferences change, on the basis of things we do know, like the present and the past, or the results of an existing or past experiment.

Mostly we guess. Some us try to systematically consider and attempt to support with evidence the guess. Lacking precision, and sometimes even accuracy, we try to avoid bad surprises. Goods ones are often welcome. If I use the NOAA weather application on my smart phone it might not surprise me to see rain pelting down at 1630 this afternoon. After all the app indicated as much. In advance of the rain I brought in chair pads and anything else that might get ruined with rain. An airline pilot knows all the defects of her aircraft. That knowledge saves lives.

Our mortal inferences, clever or dumb as they are, must have a surprise somewhere between _totally expected_, or zero surprises and thus certain 100\% of the ways to make the statement, and _totally surprising_ and 0\% chance of anticipation. We will generally be making statements like: _it will probably rain tomorrow_, or _nine times out of ten, the team with a better defense wins_. This motivates us to express our surprise in terms of plausibility and we hanker for more precision with probability.

## How many ways?

Let's use a simple example. We have four voters in an upcoming election. They may be red or blue voters. Three of us go out and talk to three voters at random, that is, indiscriminately. One of us happens to come upon a blue voter, another of us, independently, happens to find a red voter, and the other separately finds a blue voter. This is the very definition of a random sample. Each of the finders does not know what the other is doing, all three do know that there are four voters out there and they happened to have independently talked to two blue and one red voter. How many red voters and how many blue voters are there?

Here are all of the possible conjectures we can make for $blue = {\color{blue}\Box}$ and $red = {\color{red}\Box}$ voters.

```{r conjectures}
library(kableExtra)
library(knitr)

caption <- "voter conjectures"
  
conjectures <- data.frame(
  c1 = c("${\\color{red}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$"),
  c2 = c("${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$"),
  c3 = c("${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$"),
  c4 = c("${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{blue}\\Box}$")
)

colnames(conjectures) <- c("1", "2", "3", "4")

kable(conjectures, align = "c", caption = caption, escape = FALSE) %>% 
  kable_styling(full_width = F)
```

Reading this we see that there are 4 voters and 5 different voter compositions ranging from all red to all blue. Our sample is 2 blue and 1 red voter, so we can very safely eliminate the first and fifth conjectures from our analysis, but for the moment just keep them for completeness sake.

For each of the three remaining conjectures we may ask how many ways is the  conjecture _consistent_ with the collected data. For this task a tree is very helpful. Let's take the first realistic conjecture the ${\color{blue}\Box}$, ${\color{red}\Box}$, ${\color{red}\Box}$, ${\color{red}\Box}$  hypothesis and check if, when we sample all of the four voters, what are all of the ways this conjecture fans out. So here we go.

1. We sampled a ${\color{blue}\Box}$ first. How many ${\color{blue}\Box}$'s are in this version of the composition of voters? only 1.

2. We then sampled independently a ${\color{red}\Box}$. How many ${\color{red}\Box}$'s are in this conjecture? Quite a few, 3.

3. Finally we sampled a ${\color{blue}\Box}$ at random. We know there is only one ${\color{blue}\Box}$ in this version of the truth.

So, it is just counting the ways: 1 ${\color{blue}\Box}$ way $\times$ 3 ${\color{red}\Box}$ ways $\times$ 1 ${\color{blue}\Box}$ way = $1 \times 3 \times 1 = 3$ ways altogether.

When asked, many surmise that the 2 blue and 3 red conjecture is the right one. Are they right? Here is a table of the ways each conjecture pans out. We then in a separate column compute the contribution of each conjecture to the total number of ways across the conjectures, which is 3 + 8 + 9 = 20 ways. Also each of the conjecture propose a proportion $p$ of the successes, that is, the blue voters in this context. 

```{r ways-conjecture}
library(kableExtra)
library(knitr)

caption <- "ways voter conjectures turn out"
  
conjectures <- data.frame(
  c1 = c("${\\color{red}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$"),
  c2 = c("${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$"),
  c3 = c("${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{blue}\\Box}$", "${\\color{blue}\\Box}$"),
  c4 = c("${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{red}\\Box}$", "${\\color{blue}\\Box}$"),
  p =  c("0.00", "0.25", "0.50", "0.75", "1.00"),
  ways = c("0 x 4 x 0 = 0", "1 x 3 x 1 = 3", "2 x 2 x 2 = 8", "3 x 1 x 3 = 9 ", "4 x 0 x 4 = 0" ),
  relative = c( 0, 0.15, 0.40, 0.45, 0)
)

colnames(conjectures) <- c("1", "2", "3", "4", "proportion", "ways", "plausibility" )

kable(conjectures, align = "c", caption = caption, escape = FALSE) %>% 
  kable_styling(full_width = F)
```

We cannot help but note that the proportion of ways for each conjecture can range from 0, perhaps to 1, since the proportions add up to 1. The number of ways also expresses the number of true consistencies of the data with the conjecture, an enumeration of the quality of the logical compatibility of conjectures with what we observe.

We might now revise our commonsense surmise that 2 blue and 2 red is the better conjecture. However, if we use the criterion that the conjecture with the most ways consistent with the data is the best choice for a conjecture, then clearly here we would say that there are 3 blues and 1 red. Perhaps we have a better criterion that would choose our equinanimous choice of 2 blues and 2 reds? It does not appear to be so.

Ways are the count, the frequencies of logical occurrence of a hypothesis _given_ the data. The data includes the knowledge that there are possibly blues and reds, that there are 4 voters, and that we sampled 2 blues and 1 red. The relative frequency of the ways in which our conjectures are consistent with the data is what we will finally call _probability_. 

1. The plausibility is a measure between and including 0 and 1.

2. The sum of all plausibilities is 1.

3. The plausibility must be compatible with common sense.

That last requirement, in turn, requires a sketch of why it is important. 

- Let's suppose the plausibility of a proposition A (Jaynie is a runner, for example) is changed by another proposition B (Jaynie participated in a marathon). 

- Let's mix this up with the plausibility that proposition C (Jaynie is a business analyst, for example) has nothing to do with proposition B. 

- Then common sense (as opposed to common non-sense) dictates that the plausibility of A and C together (Jaynie is a business analyst runner) is also increased by proposition B.

We have just quantified the _plausibility_ of logical truth values. We have also found a very compelling criterion for the choice of a conjecture given the data and circumstances surrounding our inquiry.

## Back to data

The location and scale parameters $\mu$ and $\sigma$ (_e.g._, mean and standard deviation) we often calculate are not the mean and standard deviation of data $x$. They are not properties of the physical representation of events called **observed data**. These measures use counts of events, measures of, perhaps physical properties like heat, size, time, but in the end they are abstractions and summarizations about the events.

These parameters do carry information about the probability distribution of the representation of physical reality in data. To say $\mu$ is the mean of the data is to ascribe a mind's eye idea to the physical reality, to invest in physical, objective reality, a property that only exists in the mind, but is in fact **unobserved data**. 

This is an example of the _mind projection_ or _reification_ fallacy much in vogue in the circles of _fake_, or better yet, _chop logic_. In the same way, probabilities only exist in our minds: there is no physical reality that is a probability, just a mental construct that helps us think through potential outcomes. Is information just such a fiction?

## Checking our grip on reality

1. Suppose there are 5 voters of unknown affiliation. What is the probability that 60\% are red affiliates?

2. So one of 5 moved out and we are back to 4 voters. What is the most plausible proportion of blue voters if we sample the district and find 2 blue and 3 red voters?
